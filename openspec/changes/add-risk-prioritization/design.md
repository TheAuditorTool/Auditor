## Overview
Implement coverage-aware risk prioritization that surfaces the highest danger findings first while keeping all persistence database-first. The change introduces three new storage surfaces (coverage summary, uncovered line gaps, and finding risk metadata), a deterministic scoring module, and updated pipeline/reporting steps that publish AI-sized summaries.

## Data Model & Persistence

| Table | Purpose | Key Columns |
|-------|---------|-------------|
| `test_coverage_summary` | Stores per-file line coverage facts generated by `MetadataCollector` | `file_path`, `coverage_ratio`, `lines_executed`, `lines_missing`, timestamps |
| `test_coverage_gaps` | Tracks uncovered line numbers for coverage lookups | `file_path`, `line_number` |
| `finding_risk_scores` | Links `findings_consolidated.id` to normalized severity weight, coverage ratio, and computed `risk_score` | `finding_id`, `severity_weight`, `coverage_ratio`, `risk_score`, JSON `metadata` |

Design notes:
1. Schema defined centrally in `theauditor/indexer/schema.py` and created via `DatabaseManager.create_schema` migration branch (ALTER + CREATE statements with idempotent guards).  
2. `clear_tables` and any rebuild helpers truncate the new tables so `aud index --rebuild` maintains consistency.  
3. Coverage collectors write via two helper methods in `DatabaseManager` (`write_coverage_summary_batch`, `write_coverage_gap_batch`) to keep batching and commit strategy aligned with existing dual-write flows.

## Risk Scoring Engine

Module: `theauditor/risk_prioritizer.py`

Algorithm:
```
severity_weight = {
    "critical": 1.0,
    "high": 0.75,
    "medium": 0.5,
    "low": 0.25,
    "warning"/"info"/"style": 0.1,
}
coverage_ratio = clamp(coverage_pct / 100, 0.0, 1.0)
risk_score = severity_weight * (1.0 - coverage_ratio)
+ uncovered-line boost (adds 0.1 if finding line is explicitly uncovered, capped <=1.0)
```

Execution flow:
1. Query `findings_consolidated` for findings + join to `test_coverage_summary` on normalized file path.  
2. Fetch uncovered line data on demand to apply the boost.  
3. Normalize severities using `theauditor.utils.finding_priority.normalize_severity`.  
4. Persist results into `finding_risk_scores` (UPSERT on `finding_id`) and emit `.pf/raw/prioritized_findings.json` sorted by `risk_score DESC, severity_weight DESC, coverage_ratio ASC`.  
5. Expose a CLI command `aud prioritize` (Click group under `theauditor/commands/prioritize.py`) that wires these steps and prints a short summary (top 5 findings, highest risk).

## Pipeline & FCE Integration

Pipeline order changes (Stage 3):
1. Replace `aud metadata churn` with `aud metadata analyze --days 90` so both churn and coverage facts are available.  
2. Insert `aud prioritize` immediately after taint/pattern/graph phases so risk scores reflect final deduplicated findings.  
3. Track outputs in `.pf/raw/prioritized_findings.json` and ensure `.pf/raw/coverage_analysis.json` is still produced for human debugging.

FCE updates:
1. Join `finding_risk_scores` when loading findings (`scan_all_findings`) to attach `risk_score`, `coverage_ratio`, and uncovered-line flags.  
2. Sort `results["all_findings"]` primarily by `risk_score DESC`, then severity priority (existing `finding_priority` fallback), preserving deterministic tie-breaking.  
3. Emit risk metadata in correlation outputs to keep `/readthis` chunks informative without re-querying SQLite.

## Summary & Report Outputs

1. `aud summary` builds `summary_prioritized_part1.json` (≤100 KB) and `summary_prioritized_part2.json` if needed. Each file contains:
   - Overall stats (top risk counts, number of uncovered criticals).  
   - Top findings (id, file, line, rule, severity, risk_score, coverage_percent, uncovered flag).  
   - Cross-links pointing to `.pf/raw/prioritized_findings.json` and database table names.  
2. Per-track capsules (`summary_taint_top_risk.json`, `summary_graph_top_risk.json`, etc.) list the top N (configurable default 10) risk-ranked findings for that analyzer.  
3. Extraction/reporting modules include the new summaries in `.pf/readthis/manifest.json` so copilots can quickly locate the prioritized context.

## Verification & Testing Strategy

Automated checks:
1. Schema contract unit tests verifying new tables exist and migrate correctly (`tests/test_schema_contract.py`).  
2. New integration test `tests/test_risk_prioritizer.py` covers severity normalization, coverage join logic, uncovered-line boost, and UPSERT behavior.  
3. Pipeline smoke test extension ensuring `aud prioritize` runs during `aud full` and risk summaries are generated.  
4. Summary size test verifying combined prioritized files remain ≤100 KB (use fixture with synthetic data to assert truncation rules).

Manual verification checkpoints:
1. Run `aud metadata analyze`, confirm tables populated via `sqlite3 .pf/repo_index.db "SELECT COUNT(*) FROM test_coverage_summary"`.  
2. Execute `aud prioritize`, confirm CLI output and inspect `.pf/raw/prioritized_findings.json`.  
3. Run `aud fce` and ensure `[FCE] Sorted ...` log references risk ordering.  
4. Inspect `.pf/readthis/summary_prioritized_part1.json` and per-track capsules for structure and size.  
5. Validate overall change with `openspec validate add-risk-prioritization --strict` and project QA suite (`pytest`, `ruff`, `mypy`).
