# FCE JSON Blob Normalization

**Status**: üî¥ PROPOSAL - Awaiting Architect Approval
**Verification Status**: ‚úÖ VERIFIED - Ready for implementation after approval
**Verifier**: Opus (AI Lead Coder)
**Verification Date**: 2025-11-24
**Assigned to**: Any AI or Human following atomic tasks.md steps
**Timeline**: 3-4 days (2-3 days implementation + 1 day testing)
**Impact**: üü° **MEDIUM** - 75-700ms FCE overhead eliminated + Prevents future JSON violations
**PARALLEL-SAFE**: ‚úÖ Can run concurrently with other performance tasks (1 coordinated conflict)

---

## Why

### **Problem 1: FCE JSON Blob Overhead (75-700ms VERIFIED)**

The FCE (Findings Consolidation Engine) currently stores all finding metadata in `findings_consolidated.details_json` as a JSON TEXT blob, requiring 7 `json.loads()` calls that add 125-700ms measured overhead.

**Verification Results** (fce.py lines verified 2025-11-24):
- Line 63: `details = json.loads(details_json)` - hotspots (5-10ms)
- Line 81: `details = json.loads(details_json)` - cycles (5-10ms)
- Line 130: `details = json.loads(details_json)` - CFG complexity (10-20ms)
- Line 171: `details = json.loads(details_json)` - code churn (20-50ms)
- Line 210: `details = json.loads(details_json)` - test coverage (30-100ms)
- Line 268: `path_data = json.loads(details_json)` - **taint paths (50-500ms) ‚Üê CRITICAL BOTTLENECK**
- Line 404: `metadata = json.loads(metadata_json)` - GraphQL metadata (5-10ms)

**Total measured overhead**: 125-700ms per FCE run (92-99% reduction possible)

### **Problem 2: REVERSES Commit d8370a7 Exemption**

Commit d8370a7 (2025-10-23) established the "junction table with AUTOINCREMENT" pattern but exempted `findings_consolidated.details_json` as "Intentional findings metadata storage."

**Verification found this exemption was wrong**:
- Original assumption: "intentional metadata storage"
- Measured reality: 75-700ms overhead violates performance requirements
- **Decision**: REVERSE the exemption based on measured impact

### **Problem 3: symbols.parameters JSON Column (VERIFIED)**

Despite d8370a7, `symbols.parameters` column (core_schema.py:80) still stores JSON arrays:
```python
Column("parameters", "TEXT"),  # JSON array of parameter names: ['data', '_createdBy']
```

This violates the normalization standard and causes potential duplicate parsing.

### **Problem 4: ZERO FALLBACK Policy Violations (CRITICAL)**

**Verification found multiple violations**:
1. **fce.py lines 66-67, 93-94, 134-135, etc.**: try/except blocks catching JSON decode errors
2. **fce.py lines 465-476**: Table existence check with fallback behavior

These violations hide corruption and prevent hard failure on bad data.

### **Problem 5: No Schema Enforcement**

No mechanism prevents future developers from adding JSON blobs, allowing regression.

---

## What Changes

### **Task 5: FCE findings_consolidated.details_json Normalization**

**Create 5 normalized tables with AUTOINCREMENT pattern**:

1. **`finding_taint_paths`** (CRITICAL - eliminates 50-500ms bottleneck)
```sql
CREATE TABLE finding_taint_paths (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    finding_id TEXT NOT NULL,
    path_index INTEGER NOT NULL,      -- Preserves order
    source_file TEXT,
    source_line INTEGER,
    source_column INTEGER,
    source_name TEXT,
    source_type TEXT,
    source_pattern TEXT,
    sink_file TEXT,
    sink_line INTEGER,
    sink_column INTEGER,
    sink_name TEXT,
    sink_type TEXT,
    sink_pattern TEXT,
    path_length INTEGER,
    path_steps TEXT,                  -- Compressed intermediate steps
    confidence REAL,
    vulnerability_type TEXT,
    FOREIGN KEY (finding_id) REFERENCES findings_consolidated(id) ON DELETE CASCADE
);
CREATE INDEX idx_finding_taint_paths_finding_id ON finding_taint_paths(finding_id);
CREATE INDEX idx_finding_taint_paths_composite ON finding_taint_paths(finding_id, path_index);
```

2. **`finding_graph_hotspots`** - Graph analysis metrics (in/out degree, centrality, risk)
3. **`finding_cfg_complexity`** - Function complexity metrics (cyclomatic, cognitive, npath)
4. **`finding_metadata`** - Churn, coverage, CWE/CVE classification
5. **`symbol_parameters`** - Function/method parameters (replaces symbols.parameters column)

**Replace 7 json.loads() with indexed JOINs**:
```python
# BEFORE (50-500ms):
details = json.loads(details_json)
taint_paths = details.get('paths', [])

# AFTER (<1ms):
cursor.execute("""
    SELECT * FROM finding_taint_paths
    WHERE finding_id = ? ORDER BY path_index
""", (finding_id,))
taint_paths = cursor.fetchall()  # O(log n) indexed lookup
```

**Performance improvement**: 50-500x faster queries

### **Task 6: ZERO FALLBACK Compliance**

**Remove ALL try/except blocks** handling JSON errors:
- Delete lines 61-67, 79-94, 128-135, 169-174, 208-213, 266-273, 402-406 in fce.py
- Delete table existence check at lines 465-476
- Let database errors crash the pipeline (fail loud)

### **Task 7: Schema Contract Validation**

**Add JSON blob detector** at schema load time:
```python
def validate_no_json_blobs(tables):
    LEGITIMATE_EXCEPTIONS = {
        ('nodes', 'metadata'),           # graphs.db intentional
        ('edges', 'metadata'),           # graphs.db intentional
        ('plan_documents', 'document_json'),  # Planning system
        ('react_hooks', 'dependency_array'),  # Raw debugging
    }

    violations = []
    for table in tables:
        for column in table.columns:
            if (column.type == "TEXT" and
                (column.name.endswith('_json') or
                 column.name == 'parameters' or
                 column.name == 'dependencies')):
                if (table.name, column.name) not in LEGITIMATE_EXCEPTIONS:
                    violations.append((table.name, column.name))

    if violations:
        raise AssertionError(f"JSON violations: {violations}")
```

**Prevents future violations** by crashing at schema load if JSON detected.

### **Task 8: Connection Pooling**

**Replace 8 separate connections** with single shared connection:
- Current: 8 connections √ó 50-100ms = 400-800ms overhead
- After: 1 connection < 5ms overhead
- Additional 87% reduction in connection overhead

---

## Impact

### **Affected Files (Verified)**

| File | Lines Modified | Changes |
|------|---------------|---------|
| theauditor/fce.py | ~200 lines | Remove 7 json.loads(), add JOINs, remove try/except |
| theauditor/indexer/schemas/core_schema.py | ~300 lines | Add 5 tables, remove parameters column |
| theauditor/indexer/database/base_database.py | ~50 lines | Update writers for normalized tables |
| theauditor/taint/analysis.py | ~30 lines | Write to finding_taint_paths |
| theauditor/graph/store.py | ~30 lines | Write to finding_graph_hotspots |
| theauditor/indexer/schema.py | ~100 lines | Add JSON blob validator |
| **TOTAL** | ~710 lines | |

### **Breaking Changes (REQUIRE REINDEX)**

**Database Schema Changes**:
1. **5 New Tables Added** (finding_taint_paths, finding_graph_hotspots, etc.)
2. **2 Columns Removed** (findings_consolidated.details_json, symbols.parameters)
3. **Migration**: Run `aud full` to regenerate database (no backwards compatibility)

**External API**: Preserved - `run_fce(root_path)` signature unchanged

### **Coordination Required**

**Potential conflict with vue-inmemory-module-resolution (AI #3)**:
- Both touch javascript.py but different lines (748-768 vs 1288)
- Merge strategy: Apply both changes sequentially

---

## Testing Strategy

### **Correctness Testing**
1. Test on 10 projects with known taint findings
2. Compare FCE output before/after (must be functionally equivalent)
3. Verify taint path ordering preserved (path_index)
4. Ensure zero data loss during normalization

### **Performance Testing**
1. **Baseline**: Measure json.loads() time with cProfile (125-700ms)
2. **After**: Verify json.loads() eliminated from profiler output
3. **Target**: <10ms total overhead (92-99% reduction)
4. **Query plans**: Verify "USING INDEX" in EXPLAIN QUERY PLAN

### **ZERO FALLBACK Testing**
1. Grep for "try.*json" - must return zero results
2. Grep for table existence checks - must return zero results
3. Intentionally corrupt data and verify hard crash (no silent failures)

---

## Risk Assessment

### **Migration Risks**
| Risk | Impact | Mitigation |
|------|--------|------------|
| Data loss during migration | HIGH | Test on 10+ projects, validate row counts |
| Query performance regression | MEDIUM | Profile with EXPLAIN QUERY PLAN |
| Breaking downstream tools | HIGH | Search all details_json consumers, update each |
| Schema evolution complexity | LOW | Document all columns, use versioning |

### **Rollback Plan**
1. Revert schema changes (remove new tables)
2. Restore JSON columns (re-add details_json, parameters)
3. Git revert FCE changes
4. Run `aud full` to regenerate old schema
5. **Time to rollback**: ~30 minutes

---

## Success Criteria

**ALL must be met**:

1. ‚úÖ FCE overhead reduced: 125-700ms ‚Üí <10ms (92-99% reduction)
2. ‚úÖ Zero JSON TEXT columns (except 4 documented exemptions)
3. ‚úÖ All tests passing (zero regressions)
4. ‚úÖ No data loss (row counts match)
5. ‚úÖ Schema validator prevents future violations
6. ‚úÖ ZERO FALLBACK compliance (no try/except, no fallbacks)
7. ‚úÖ Connection pooling implemented (8 ‚Üí 1 connection)

---

## Approval Gates

### **Stage 1: Proposal Review** ‚Üê CURRENT
- [x] Prime Directive verification completed
- [x] All 7 json.loads() verified with line numbers
- [x] Commit d8370a7 exemption analyzed
- [x] ZERO FALLBACK violations identified
- [ ] **Architect approves REVERSING commit d8370a7 exemption**
- [ ] **Architect approves breaking backwards compatibility**

### **Stage 2: Implementation**
- [ ] Implement Tasks 5.1-5.7 (FCE normalization)
- [ ] Implement Tasks 6.1-6.6 (symbols.parameters normalization)
- [ ] Implement Tasks 7.1-7.3 (schema validator)
- [ ] Implement Task 8 (connection pooling)

### **Stage 3: Validation**
- [ ] Performance improvement verified (>90% reduction)
- [ ] Zero data loss confirmed
- [ ] All tests passing
- [ ] ZERO FALLBACK compliance verified

### **Stage 4: Deployment**
- [ ] Merged to main branch
- [ ] Documentation updated
- [ ] Users notified of breaking change

---

## Dependencies

### **Prerequisites (VERIFIED)**
- ‚úÖ Schema system supports junction tables
- ‚úÖ Commit d8370a7 pattern established
- ‚úÖ AUTOINCREMENT proven to work
- ‚úÖ Foreign keys supported (though disabled)

### **Required Reading Before Implementation**
1. This proposal's `verification.md` - All verification results
2. This proposal's `design.md` - Technical decisions explained
3. This proposal's `tasks.md` - Atomic implementation steps
4. `teamsop.md` v4.20 - Prime Directive requirements
5. `CLAUDE.md` lines 194-249 - ZERO FALLBACK policy
6. Commit d8370a7 full diff - Junction table pattern

---

## Related Changes

**Parent**: `performance-revolution-now` (PAUSED AND SPLIT into 5 proposals)

**Siblings** (can run in parallel):
- `taint-analysis-spatial-indexes` (AI #1) - No conflicts
- `fix-python-ast-orchestrator` (AI #2) - No conflicts
- `vue-inmemory-module-resolution` (AI #3) - 1 file overlap (coordinate)
- `database-indexes-cleanup` (TIER 2) - No conflicts

---

## Open Questions (Resolved)

1. **Should we reverse commit d8370a7 exemption?**
   - **Answer**: YES - Performance data (75-700ms) justifies reversal

2. **Should path_steps be TEXT or normalized?**
   - **Answer**: TEXT for now, normalize if >1KB average

3. **Should we add database triggers?**
   - **Answer**: NO - Validate in Python for debuggability

4. **Should we version the schema?**
   - **Answer**: YES - Add schema_version table in separate PR

---

## Architect Decision Required

**This proposal REVERSES the exemption granted in commit d8370a7** for `findings_consolidated.details_json`.

**Original exemption** (2025-10-23): "Intentional findings metadata storage"
**Measured impact** (2025-11-24): 75-700ms overhead, 50-500ms for taint paths alone
**Recommendation**: REVERSE based on performance measurements

**Required Approval**:
- [ ] **APPROVED** - Reverse exemption, proceed with normalization
- [ ] **DENIED** - Keep exemption, close this proposal

---

**Next Step**: Architect reviews verification results and approves/denies reversal of commit d8370a7 exemption